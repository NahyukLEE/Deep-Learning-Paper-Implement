{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "tamil-place",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Module Import\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dress-spyware",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch version: 1.8.1  Device: cuda\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device('cuda')\n",
    "else :\n",
    "    DEVICE = torch.device('cpu')\n",
    "\n",
    "print('Using PyTorch version:', torch.__version__, ' Device:', DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "quick-forum",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "EPOCHS = 90"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cordless-lending",
   "metadata": {},
   "source": [
    "## Dataset Loading (CalTech101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "framed-booking",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.Resize((227,227)),\n",
    "                    transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "palestinian-driving",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "caltech_dataset = datasets.Caltech101(root = './data/Caltech101',\n",
    "                                 download = True,\n",
    "                                 transform = transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bibliographic-scanning",
   "metadata": {},
   "source": [
    "#### Train:Validation:Test = 7:1:2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "likely-johnston",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.8 * len(caltech_dataset))\n",
    "test_size = len(caltech_dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(caltech_dataset, [train_size, test_size])\n",
    "\n",
    "train_size = int(0.875 * train_size)\n",
    "valid_size = len(train_dataset) - train_size\n",
    "train_dataset, valid_dataset = torch.utils.data.random_split(train_dataset, [train_size, valid_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "minus-eagle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train dataset size :  6073 (0.70)\n",
      "validation dataset size :  868 (0.10)\n",
      "test dataset size :  1736 (0.20)\n"
     ]
    }
   ],
   "source": [
    "print('train dataset size : ', len(train_dataset), '(%.2f)' %(len(train_dataset)/len(caltech_dataset)))\n",
    "print('validation dataset size : ', len(valid_dataset), '(%.2f)' %(len(valid_dataset)/len(caltech_dataset)))\n",
    "print('test dataset size : ', len(test_dataset), '(%.2f)' %(len(test_dataset)/len(caltech_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "silver-creation",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=train_dataset, shuffle=True, batch_size=BATCH_SIZE)\n",
    "val_loader = DataLoader(dataset=valid_dataset, shuffle=False, batch_size=BATCH_SIZE)\n",
    "test_loader = DataLoader(dataset=test_dataset, shuffle=False, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "treated-phoenix",
   "metadata": {},
   "source": [
    "## Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "wireless-comparative",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_output_size(input_size, kernel_size, padding_size, stride):\n",
    "    output = (input_size - kernel_size + 2 * padding_size) / stride + 1\n",
    "    return output\n",
    "\n",
    "def maxpool_output_size(input_size, pooling_size, stride):\n",
    "    output = (input_size - pooling_size) / stride + 1\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "crazy-closing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27.0"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1st conv output size\n",
    "maxpool_output_size(conv_output_size(227, 11, 0, 4),3,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "corresponding-graph",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.0"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2nd conv+maxpooing output size\n",
    "maxpool_output_size(conv_output_size(27,3,1,1),3,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "sixth-married",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.0"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3rd conv output size\n",
    "conv_output_size(13,3,1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "formal-notice",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.0"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4th conv output size\n",
    "conv_output_size(13,3,1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "divided-perspective",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.0"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5th conv+maxpooing output size\n",
    "maxpool_output_size(conv_output_size(13,3,1,1),3,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "searching-constraint",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlexNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.convLayer = nn.Sequential(\n",
    "            # --- 1st Convolutional layer ---\n",
    "            nn.Conv2d(in_channel = 3, \n",
    "                      out_channel = 96,\n",
    "                      kernel_size = 11,\n",
    "                      stride = 4),\n",
    "            nn.ReLU(),\n",
    "            nn.LocalResponseNorm(size = 5,\n",
    "                                alpha = 0.0001,\n",
    "                                beta = 0.75,\n",
    "                                k = 2),\n",
    "            nn.MaxPool2d(kernel_size = 3, stride = 2),\n",
    "            \n",
    "            # --- 2nd Convolutional layer ---\n",
    "            nn.Conv2d(in_channel = 96,\n",
    "                      out_channel = 256,\n",
    "                      kernel_size = 5,\n",
    "                      stride = 1,\n",
    "                      padding = 1),\n",
    "            nn.ReLU(),\n",
    "            nn.LocalResponseNorm(size = 5,\n",
    "                    alpha = 0.0001,\n",
    "                    beta = 0.75,\n",
    "                    k = 2),\n",
    "            nn.MaxPool2d(kernel_size = 3, stride = 2),\n",
    "            \n",
    "            # --- 3rd Convolutional layer ---\n",
    "            nn.Conv2d(in_channel = 256,\n",
    "                     out_channel = 384,\n",
    "                     kernel_size = 3,\n",
    "                     stride = 1,\n",
    "                     padding = 1),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            # --- 4th Convolutional layer ---\n",
    "            nn.Conv2d(in_channel = 384,\n",
    "                     out_channel = 384,\n",
    "                     kernel_size = 3,\n",
    "                     stride = 1,\n",
    "                     padding = 1),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            # --- 5th Convolutional layer ---\n",
    "            nn.Conv2d(in_channel = 384,\n",
    "                     out_channel = 256,\n",
    "                     kernel_size = 3,\n",
    "                      stride = 1,\n",
    "                      padding = 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 3, stride = 2),\n",
    "        )\n",
    "        \n",
    "        self.fcLayer = nn.Sequential(\n",
    "            # --- 1st Fully Connected layer ---\n",
    "            nn.Linear(256*6*6, 4096), # channel * size, output_channel\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p = 0.5),\n",
    "            \n",
    "            # --- 2nd Fully Connected layer ---\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLu(),\n",
    "            nn.Dropout(p = 0.5),\n",
    "        )\n",
    "    \n",
    "    def forward(self, train):\n",
    "        output = self.convLayer(train)\n",
    "        output = self.fcLayer(output)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statewide-gates",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
